# Attention is all you need

## Objective
Reverse engineer a transformer from "Attention is all you need" by Vaswani et all.

### Introduction
The transformer model, introduced in the groundbreaking paper "Attention is All You Need" by Vaswani et al., has revolutionized the field of natural language processing (NLP) and beyond. At its core, the transformer model utilizes a mechanism known as "self-attention" to process sequences of data in parallel, enabling more efficient and effective learning from large datasets. This architecture has paved the way for the development of highly sophisticated models such as GPT (Generative Pre-trained Transformer) and BERT (Bidirectional Encoder Representations from Transformers), which have set new standards for a variety of tasks including machine translation, text generation, and semantic analysis. This project aims to reverse engineer the transformer model from Vaswani et al.'s paper, with the objective of gaining a deeper understanding of its mechanisms and applications. Through a meticulous process of writing pseudo code, implementing the model in Python, and thoroughly documenting the development process, this endeavor seeks to demystify the inner workings of transformers and contribute to the broader knowledge base surrounding this influential architecture.

### Requirements
You will need the most updated version of Python, and Pytorch

### Project Structure
- transformer.py: The main Python script implementing the transformer model based on the pseudo code
- pseudo_code.md: Contains the initial pseudo code outlining the logic and structure of the transformer model
- documentation.md: Detailed documentation of the code and the model architecture.
- diagrams/: Directory containing any diagrams or visual representations of the model.

### Coding Procedures
I plan to use the following procedures:
- First write psuedo code in script.
- Write code based on pseudo code.
- Add comments explaining code as required.
- Document code in separate file.
- Capture pseudo code in separate file.
- Create diagram as appropriate.  I may decide to change this, as the peer reviewed articles typically do this already.

### Skills Learned
- Deep Understanding of Transformer Architecture: Gained comprehensive insights into the transformer model, including its core components like self-attention mechanisms, positional encoding, and the overall architecture comprising encoder and decoder stacks.
- Advanced Python Programming: Enhanced Python programming skills, especially in writing efficient, clean, and well-documented code suitable for implementing complex machine learning models.
- Machine Learning Implementation: Learned how to implement and train a sophisticated machine learning model from scratch using PyTorch, a leading library for building neural networks.
- Pseudo Code Development: Improved the ability to translate complex algorithms and ideas into pseudo code, facilitating a clearer understanding and more structured approach to coding the final solution.
- Code Documentation and Annotation: Developed skills in writing comprehensive documentation and in-line comments to explain the logic and functionality of the code, making it accessible to others for learning and collaboration.
- Diagram Creation and Interpretation: Learned to create and interpret diagrams that represent the model architecture, contributing to a better grasp of the overall structure and flow of data through the transformer model.
- Problem-Solving and Debugging: Enhanced problem-solving skills, including debugging and refining code to improve model performance and accuracy.
- Research and Critical Analysis: Cultivated the ability to engage with academic literature, critically analyze research papers, and apply findings to practical implementation challenges.

### Tools Used
- Python, Pytorch
- Pyreverse for developing UML

### References
- Vaswani, A., et al. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).